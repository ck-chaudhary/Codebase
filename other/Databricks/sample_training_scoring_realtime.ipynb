{"cells":[{"cell_type":"markdown","source":["## Binary classification example - Training, Evaluating Classifiers with `mmlspark` along with how to create a web service using MMLSpark Serving \n\nIn this example, we try to predict incomes from the *Adult Census* dataset. Then using MMLSpark serving create a web service. \n\nFirst, we import the packages (use `help(mmlspark)` to view contents),"],"metadata":{}},{"cell_type":"code","source":["import sys"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport mmlspark\n\n# help(mmlspark)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["Now let's read the data and split it to train and test sets:"],"metadata":{}},{"cell_type":"code","source":["dataFilePath = \"AdultCensusIncome.csv\"\nimport os, urllib\nif not os.path.isfile(dataFilePath):\n    urllib.urlretrieve(\"https://mmlspark.azureedge.net/datasets/\" + dataFilePath, dataFilePath)\ndata = spark.createDataFrame(pd.read_csv(dataFilePath, dtype={\" hours-per-week\": np.float64}))\ndata = data.select([\" education\", \" marital-status\", \" hours-per-week\", \" income\"])\ntrain, test = data.randomSplit([0.75, 0.25], seed=123)\ntrain.limit(10).toPandas()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["`TrainClassifier` can be used to initialize and fit a model, it wraps SparkML classifiers.\nYou can use `help(mmlspark.TrainClassifier)` to view the different parameters.\n\nNote that it implicitly converts the data into the format expected by the algorithm: tokenize\nand hash strings, one-hot encodes categorical variables, assembles the features into a vector\nand so on.  The parameter `numFeatures` controls the number of hashed features."],"metadata":{}},{"cell_type":"code","source":["from mmlspark import TrainClassifier\nfrom pyspark.ml.classification import LogisticRegression\nmodel = TrainClassifier(model=LogisticRegression(), labelCol=\" income\", numFeatures=256).fit(train)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["After the model is trained, we score it against the test dataset and view metrics."],"metadata":{}},{"cell_type":"code","source":["from mmlspark import ComputeModelStatistics, TrainedClassifierModel\nprediction = model.transform(test)\nprediction.head(5)\ntest.printSchema()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["metrics = ComputeModelStatistics().transform(prediction)\nmetrics.limit(10).toPandas()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Link to documentation: https://github.com/Azure/mmlspark/blob/master/docs/mmlspark-serving.md "],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Determine the schema for the input row for the webservice"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import length, col, lit, to_json, struct\n\nrow = test.select(to_json(struct(\"*\")).alias(\"json\")).take(1)[0]\nrow.json"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Define the webservice input/output"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import length, col, lit, from_json\nfrom pyspark.sql.types import *\nimport uuid\nimport requests\n\n\nserving_inputs = spark.readStream.server() \\\n    .address(\"localhost\", 8888, \"my_api\") \\\n    .load()\\\n    .withColumn(\"variables\", from_json(col(\"value\"), test.schema))\\\n    .select(\"id\",\"variables.*\")\n    \nserving_outputs = model.transform(serving_inputs) \\\n  .withColumn(\"scored_labels\", col(\"scored_labels\").cast(\"string\"))\n\nserving_outputs.writeStream \\\n    .server() \\\n    .option(\"name\", \"my_api\") \\\n    .queryName(\"my_query\") \\\n    .option(\"replyCol\", \"scored_labels\") \\\n    .option(\"checkpointLocation\", \"checkpoints-{}\".format(uuid.uuid1())) \\\n    .start()\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["Test the webservice"],"metadata":{}},{"cell_type":"code","source":["import requests\nimport base64\n\ndata = u'{\" education\":\" 10th\",\" marital-status\":\" Divorced\",\" hours-per-week\":40.0,\" income\":\" <=50K\"}'\nr = requests.post(data=data, url=\"http://localhost:8888/my_api\")\nprint(r.text)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":18}],"metadata":{"language_info":{"codemirror_mode":{"name":"python","version":"3"},"mimetype":"text/x-python","name":"pyspark3","pygments_lexer":"python3"},"name":"sample_training_scoring_realtime","notebookId":2639256844899532,"kernelspec":{"display_name":"PySpark3","language":"","name":"pyspark3kernel"},"anaconda-cloud":{}},"nbformat":4,"nbformat_minor":0}
